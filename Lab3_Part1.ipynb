{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":1246668,"sourceType":"datasetVersion","datasetId":715814}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-04T14:50:22.158544Z","iopub.execute_input":"2024-09-04T14:50:22.159579Z","iopub.status.idle":"2024-09-04T14:50:22.571881Z","shell.execute_reply.started":"2024-09-04T14:50:22.159511Z","shell.execute_reply":"2024-09-04T14:50:22.570823Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/glove6b100dtxt/glove.6B.100d.txt\n/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==2.2.1 torchtext==0.17.1","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:50:22.573771Z","iopub.execute_input":"2024-09-04T14:50:22.574240Z","iopub.status.idle":"2024-09-04T14:53:23.929817Z","shell.execute_reply.started":"2024-09-04T14:50:22.574201Z","shell.execute_reply":"2024-09-04T14:53:23.928270Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch==2.2.1\n  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchtext==0.17.1\n  Downloading torchtext-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.1) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.1)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.17.1) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.17.1) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.17.1) (1.26.4)\nCollecting torchdata==0.7.1 (from torchtext==0.17.1)\n  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1)\n  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.1->torchtext==0.17.1) (1.26.18)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.1) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.17.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.17.1) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.17.1) (2024.7.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.1) (1.3.0)\nDownloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchdata, torchtext\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0+cpu\n    Uninstalling torch-2.4.0+cpu:\n      Successfully uninstalled torch-2.4.0+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.2.1 which is incompatible.\ntorchvision 0.19.0+cpu requires torch==2.4.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 torchdata-0.7.1 torchtext-0.17.1 triton-2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nimport re\nfrom tqdm import tqdm\ntqdm.pandas()\n\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:41.920216Z","iopub.execute_input":"2024-09-04T14:57:41.920658Z","iopub.status.idle":"2024-09-04T14:57:41.932243Z","shell.execute_reply.started":"2024-09-04T14:57:41.920618Z","shell.execute_reply":"2024-09-04T14:57:41.931054Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('//kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:54:34.298397Z","iopub.execute_input":"2024-09-04T14:54:34.298834Z","iopub.status.idle":"2024-09-04T14:54:35.784893Z","shell.execute_reply.started":"2024-09-04T14:54:34.298793Z","shell.execute_reply":"2024-09-04T14:54:35.783850Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize stopwords\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    # Lowercase\n    text = text.lower()\n    # Remove HTML tags\n    text = re.sub(r'<.*?>', '', text)\n    # Remove special characters and numbers\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Tokenize\n    tokens = word_tokenize(text)\n    # Remove stopwords\n    tokens = [word for word in tokens if word not in stop_words]\n    return tokens\n\n# Apply preprocessing\ndf['clean_review'] = df['review'].progress_apply(preprocess_text)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:55:10.375364Z","iopub.execute_input":"2024-09-04T14:55:10.375795Z","iopub.status.idle":"2024-09-04T14:55:59.854598Z","shell.execute_reply.started":"2024-09-04T14:55:10.375753Z","shell.execute_reply":"2024-09-04T14:55:59.853449Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 50000/50000 [00:49<00:00, 1011.80it/s]\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                        clean_review  \n0  [one, reviewers, mentioned, watching, oz, epis...  \n1  [wonderful, little, production, filming, techn...  \n2  [thought, wonderful, way, spend, time, hot, su...  \n3  [basically, theres, family, little, boy, jake,...  \n4  [petter, matteis, love, time, money, visually,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>clean_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>[wonderful, little, production, filming, techn...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>[basically, theres, family, little, boy, jake,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>[petter, matteis, love, time, money, visually,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_dict = {'positive': 1, 'negative': 0}\ndf['label'] = df['sentiment'].map(label_dict)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:55:59.856912Z","iopub.execute_input":"2024-09-04T14:55:59.857440Z","iopub.status.idle":"2024-09-04T14:55:59.881504Z","shell.execute_reply.started":"2024-09-04T14:55:59.857384Z","shell.execute_reply":"2024-09-04T14:55:59.880471Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  \\\n0  One of the other reviewers has mentioned that ...  positive   \n1  A wonderful little production. <br /><br />The...  positive   \n2  I thought this was a wonderful way to spend ti...  positive   \n3  Basically there's a family where a little boy ...  negative   \n4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n\n                                        clean_review  label  \n0  [one, reviewers, mentioned, watching, oz, epis...      1  \n1  [wonderful, little, production, filming, techn...      1  \n2  [thought, wonderful, way, spend, time, hot, su...      1  \n3  [basically, theres, family, little, boy, jake,...      0  \n4  [petter, matteis, love, time, money, visually,...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>clean_review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>[wonderful, little, production, filming, techn...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>[basically, theres, family, little, boy, jake,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>[petter, matteis, love, time, money, visually,...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df['clean_review']\ny = df['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:56:41.513426Z","iopub.execute_input":"2024-09-04T14:56:41.514559Z","iopub.status.idle":"2024-09-04T14:56:41.548569Z","shell.execute_reply.started":"2024-09-04T14:56:41.514507Z","shell.execute_reply":"2024-09-04T14:56:41.547316Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\n# Build vocabulary\nall_words = [word for tokens in X_train for word in tokens]\nword_counts = Counter(all_words)\nvocab = sorted(word_counts, key=word_counts.get, reverse=True)\nvocab_size = len(vocab)\n\nprint(f\"Vocab size: {vocab_size}\")\n\n# Word to index mapping\nword_to_idx = {word: idx+2 for idx, word in enumerate(vocab)}\nword_to_idx[\"<PAD>\"] = 0\nword_to_idx[\"<UNK>\"] = 1\n\n# Index to word mapping\nidx_to_word = {idx: word for word, idx in word_to_idx.items()}","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:14.718788Z","iopub.execute_input":"2024-09-04T14:57:14.719209Z","iopub.status.idle":"2024-09-04T14:57:16.674201Z","shell.execute_reply.started":"2024-09-04T14:57:14.719155Z","shell.execute_reply":"2024-09-04T14:57:16.672875Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Vocab size: 186211\n","output_type":"stream"}]},{"cell_type":"code","source":"def encode_text(text):\n    return [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in text]\n\n# Encode training and testing data\nX_train_enc = X_train.apply(encode_text)\nX_test_enc = X_test.apply(encode_text)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:27.791261Z","iopub.execute_input":"2024-09-04T14:57:27.791716Z","iopub.status.idle":"2024-09-04T14:57:31.305253Z","shell.execute_reply.started":"2024-09-04T14:57:27.791670Z","shell.execute_reply":"2024-09-04T14:57:31.303697Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def pad_sequences(sequences, max_len):\n    sequences = [torch.tensor(seq[:max_len]) for seq in sequences]\n    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=word_to_idx[\"<PAD>\"])\n    return sequences_padded\n\nmax_len = 200  # Define max length\n\nX_train_padded = pad_sequences(X_train_enc, max_len)\nX_test_padded = pad_sequences(X_test_enc, max_len)\n\n# Convert labels to tensors\ny_train_tensor = torch.tensor(y_train.values)\ny_test_tensor = torch.tensor(y_test.values)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:57:53.789896Z","iopub.execute_input":"2024-09-04T14:57:53.790722Z","iopub.status.idle":"2024-09-04T14:57:55.614071Z","shell.execute_reply.started":"2024-09-04T14:57:53.790665Z","shell.execute_reply":"2024-09-04T14:57:55.612730Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(X_train_padded, y_train_tensor)\ntest_dataset = torch.utils.data.TensorDataset(X_test_padded, y_test_tensor)\n\nbatch_size = 64\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:58:06.393099Z","iopub.execute_input":"2024-09-04T14:58:06.393591Z","iopub.status.idle":"2024-09-04T14:58:06.401301Z","shell.execute_reply.started":"2024-09-04T14:58:06.393548Z","shell.execute_reply":"2024-09-04T14:58:06.400012Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 100\nglove_path = '/kaggle/input/glove6b100dtxt/glove.6B.100d.txt'\n\n# Load GloVe embeddings\nembeddings_index = {}\nwith open(glove_path, encoding='utf8') as f:\n    for line in tqdm(f, desc=\"Loading GloVe\"):\n        values = line.strip().split()\n        word = values[0]\n        coeffs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coeffs\n\nprint(f\"Loaded {len(embeddings_index)} word vectors.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:58:42.414124Z","iopub.execute_input":"2024-09-04T14:58:42.414642Z","iopub.status.idle":"2024-09-04T14:58:54.571567Z","shell.execute_reply.started":"2024-09-04T14:58:42.414600Z","shell.execute_reply":"2024-09-04T14:58:54.570479Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Loading GloVe: 400000it [00:12, 32936.86it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded 400000 word vectors.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size + 2, embedding_dim))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:01.563021Z","iopub.execute_input":"2024-09-04T14:59:01.563865Z","iopub.status.idle":"2024-09-04T14:59:01.568978Z","shell.execute_reply.started":"2024-09-04T14:59:01.563817Z","shell.execute_reply":"2024-09-04T14:59:01.567907Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for word, idx in word_to_idx.items():\n    if word in embeddings_index:\n        embedding_matrix[idx] = embeddings_index[word]\n    else:\n        # Initialize random embedding for words not in GloVe\n        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:11.028308Z","iopub.execute_input":"2024-09-04T14:59:11.028718Z","iopub.status.idle":"2024-09-04T14:59:12.221350Z","shell.execute_reply.started":"2024-09-04T14:59:11.028680Z","shell.execute_reply":"2024-09-04T14:59:12.220401Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Convert to tensor\nembedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\nprint(f\"Embedding matrix shape: {embedding_matrix.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:22.699413Z","iopub.execute_input":"2024-09-04T14:59:22.699822Z","iopub.status.idle":"2024-09-04T14:59:22.768087Z","shell.execute_reply.started":"2024-09-04T14:59:22.699784Z","shell.execute_reply":"2024-09-04T14:59:22.766734Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Embedding matrix shape: torch.Size([186213, 100])\n","output_type":"stream"}]},{"cell_type":"code","source":"class RNNClassifier(nn.Module):\n    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n        super(RNNClassifier, self).__init__()\n        vocab_size, embedding_dim = embedding_matrix.shape\n\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(drop_prob)\n\n    def forward(self, x):\n        embeds = self.embedding(x)\n        rnn_out, hidden = self.rnn(embeds)\n        out = self.dropout(hidden[-1])\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:32.782428Z","iopub.execute_input":"2024-09-04T14:59:32.782870Z","iopub.status.idle":"2024-09-04T14:59:32.791456Z","shell.execute_reply.started":"2024-09-04T14:59:32.782818Z","shell.execute_reply":"2024-09-04T14:59:32.790233Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, embedding_matrix, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n        super(LSTMClassifier, self).__init__()\n        vocab_size, embedding_dim = embedding_matrix.shape\n\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(drop_prob)\n\n    def forward(self, x):\n        embeds = self.embedding(x)\n        lstm_out, (hidden, cell) = self.lstm(embeds)\n        out = self.dropout(hidden[-1])\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:41.849327Z","iopub.execute_input":"2024-09-04T14:59:41.849735Z","iopub.status.idle":"2024-09-04T14:59:41.857549Z","shell.execute_reply.started":"2024-09-04T14:59:41.849690Z","shell.execute_reply":"2024-09-04T14:59:41.856430Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device):\n    model.to(device)\n    best_valid_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        epoch_acc = 0\n\n        for texts, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            texts = texts.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            predictions = model(texts)\n            loss = criterion(predictions.squeeze(), labels.float())\n            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n            acc = (preds == labels).float().mean()\n\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n\n        valid_loss, valid_acc = evaluate_model(model, valid_loader, criterion, device)\n\n        print(f'\\nEpoch {epoch+1}/{epochs}')\n        print(f'Train Loss: {epoch_loss/len(train_loader):.3f} | Train Acc: {epoch_acc/len(train_loader):.3f}')\n        print(f'Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.3f}')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:59:52.842522Z","iopub.execute_input":"2024-09-04T14:59:52.842963Z","iopub.status.idle":"2024-09-04T14:59:52.852987Z","shell.execute_reply.started":"2024-09-04T14:59:52.842921Z","shell.execute_reply":"2024-09-04T14:59:52.851798Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    epoch_acc = 0\n\n    with torch.no_grad():\n        for texts, labels in data_loader:\n            texts = texts.to(device)\n            labels = labels.to(device)\n\n            predictions = model(texts)\n            loss = criterion(predictions.squeeze(), labels.float())\n            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n            acc = (preds == labels).float().mean()\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n\n    return epoch_loss / len(data_loader), epoch_acc / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T15:00:02.203658Z","iopub.execute_input":"2024-09-04T15:00:02.204250Z","iopub.status.idle":"2024-09-04T15:00:02.213808Z","shell.execute_reply.started":"2024-09-04T15:00:02.204172Z","shell.execute_reply":"2024-09-04T15:00:02.212646Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nhidden_dim = 128\noutput_dim = 1\nn_layers = 2\nepochs = 5\nlearning_rate = 0.001\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model, criterion and optimizer\nrnn_model = RNNClassifier(embedding_matrix, hidden_dim, output_dim, n_layers)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(rnn_model.parameters(), lr=learning_rate)\n\n# Train the model\ntrained_rnn_model = train_model(rnn_model, train_loader, test_loader, criterion, optimizer,epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T15:02:40.557788Z","iopub.execute_input":"2024-09-04T15:02:40.558220Z","iopub.status.idle":"2024-09-04T16:04:32.393845Z","shell.execute_reply.started":"2024-09-04T15:02:40.558157Z","shell.execute_reply":"2024-09-04T16:04:32.391943Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 625/625 [12:58<00:00,  1.24s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTrain Loss: 0.699 | Train Acc: 0.502\nVal. Loss: 0.692 |  Val. Acc: 0.508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 625/625 [12:50<00:00,  1.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTrain Loss: 0.693 | Train Acc: 0.511\nVal. Loss: 0.690 |  Val. Acc: 0.514\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 625/625 [10:44<00:00,  1.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTrain Loss: 0.694 | Train Acc: 0.512\nVal. Loss: 0.692 |  Val. Acc: 0.530\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 625/625 [12:39<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTrain Loss: 0.693 | Train Acc: 0.520\nVal. Loss: 0.691 |  Val. Acc: 0.531\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 625/625 [12:07<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTrain Loss: 0.693 | Train Acc: 0.524\nVal. Loss: 0.692 |  Val. Acc: 0.531\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize model, criterion and optimizer\nlstm_model = LSTMClassifier(embedding_matrix, hidden_dim, output_dim, n_layers)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(lstm_model.parameters(), lr=learning_rate)\n\n# Train the model\ntrained_lstm_model = train_model(lstm_model, train_loader, test_loader, criterion, optimizer, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T16:04:32.398123Z","iopub.execute_input":"2024-09-04T16:04:32.400596Z","iopub.status.idle":"2024-09-04T16:59:07.281673Z","shell.execute_reply.started":"2024-09-04T16:04:32.400529Z","shell.execute_reply":"2024-09-04T16:59:07.280452Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 625/625 [21:47<00:00,  2.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTrain Loss: 0.690 | Train Acc: 0.513\nVal. Loss: 0.693 |  Val. Acc: 0.508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 625/625 [12:10<00:00,  1.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTrain Loss: 0.686 | Train Acc: 0.523\nVal. Loss: 0.678 |  Val. Acc: 0.532\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 625/625 [07:00<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTrain Loss: 0.586 | Train Acc: 0.693\nVal. Loss: 0.470 |  Val. Acc: 0.812\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 625/625 [06:11<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTrain Loss: 0.394 | Train Acc: 0.845\nVal. Loss: 0.359 |  Val. Acc: 0.838\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 625/625 [06:03<00:00,  1.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTrain Loss: 0.273 | Train Acc: 0.897\nVal. Loss: 0.333 |  Val. Acc: 0.872\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_model(model, data_loader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for texts, labels in data_loader:\n            texts = texts.to(device)\n            labels = labels.to(device)\n\n            predictions = model(texts)\n            preds = torch.round(torch.sigmoid(predictions.squeeze()))\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds, target_names=['Negative', 'Positive'])\n\n    print(f'Accuracy: {acc:.3f}')\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:10:51.653855Z","iopub.execute_input":"2024-09-04T17:10:51.654333Z","iopub.status.idle":"2024-09-04T17:10:51.662664Z","shell.execute_reply.started":"2024-09-04T17:10:51.654291Z","shell.execute_reply":"2024-09-04T17:10:51.661400Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"RNN Model Evaluation:\")\ntest_model(trained_rnn_model, test_loader, device)\n\nprint(\"LSTM Model Evaluation:\")\ntest_model(trained_lstm_model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:10:58.686746Z","iopub.execute_input":"2024-09-04T17:10:58.687170Z","iopub.status.idle":"2024-09-04T17:11:21.968799Z","shell.execute_reply.started":"2024-09-04T17:10:58.687131Z","shell.execute_reply":"2024-09-04T17:11:21.967481Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"RNN Model Evaluation:\nAccuracy: 0.562\n              precision    recall  f1-score   support\n\n    Negative       0.55      0.62      0.58      4961\n    Positive       0.57      0.51      0.54      5039\n\n    accuracy                           0.56     10000\n   macro avg       0.56      0.56      0.56     10000\nweighted avg       0.56      0.56      0.56     10000\n\nLSTM Model Evaluation:\nAccuracy: 0.872\n              precision    recall  f1-score   support\n\n    Negative       0.88      0.85      0.87      4961\n    Positive       0.86      0.89      0.88      5039\n\n    accuracy                           0.87     10000\n   macro avg       0.87      0.87      0.87     10000\nweighted avg       0.87      0.87      0.87     10000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class RNNClassifierOnTheFly(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n        super(RNNClassifierOnTheFly, self).__init__()\n\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(drop_prob)\n\n    def forward(self, x):\n        embeds = self.embedding(x)\n        rnn_out, hidden = self.rnn(embeds)\n        out = self.dropout(hidden[-1])\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:11:21.970761Z","iopub.execute_input":"2024-09-04T17:11:21.971120Z","iopub.status.idle":"2024-09-04T17:11:21.980293Z","shell.execute_reply.started":"2024-09-04T17:11:21.971079Z","shell.execute_reply":"2024-09-04T17:11:21.978932Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifierOnTheFly(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n        super(LSTMClassifierOnTheFly, self).__init__()\n\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(drop_prob)\n\n    def forward(self, x):\n        embeds = self.embedding(x)\n        lstm_out, (hidden, cell) = self.lstm(embeds)\n        out = self.dropout(hidden[-1])\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:11:21.982061Z","iopub.execute_input":"2024-09-04T17:11:21.982546Z","iopub.status.idle":"2024-09-04T17:11:21.999350Z","shell.execute_reply.started":"2024-09-04T17:11:21.982500Z","shell.execute_reply":"2024-09-04T17:11:21.998175Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nembedding_dim = 100  # Same as GloVe\nhidden_dim = 128\noutput_dim = 1\nn_layers = 2\nepochs = 5\nlearning_rate = 0.001\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model, criterion, and optimizer\nrnn_model_otf = RNNClassifierOnTheFly(len(word_to_idx), embedding_dim, hidden_dim, output_dim, n_layers)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(rnn_model_otf.parameters(), lr=learning_rate)\n\n# Train the model\ntrained_rnn_model_otf = train_model(rnn_model_otf, train_loader, test_loader, criterion, optimizer, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:11:22.001481Z","iopub.execute_input":"2024-09-04T17:11:22.001901Z","iopub.status.idle":"2024-09-04T18:26:09.899371Z","shell.execute_reply.started":"2024-09-04T17:11:22.001859Z","shell.execute_reply":"2024-09-04T18:26:09.898220Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 625/625 [16:01<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5\nTrain Loss: 0.701 | Train Acc: 0.500\nVal. Loss: 0.695 |  Val. Acc: 0.505\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 625/625 [17:34<00:00,  1.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\nTrain Loss: 0.694 | Train Acc: 0.503\nVal. Loss: 0.695 |  Val. Acc: 0.501\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 625/625 [14:43<00:00,  1.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\nTrain Loss: 0.692 | Train Acc: 0.517\nVal. Loss: 0.695 |  Val. Acc: 0.500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 625/625 [13:06<00:00,  1.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\nTrain Loss: 0.681 | Train Acc: 0.530\nVal. Loss: 0.707 |  Val. Acc: 0.501\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 625/625 [12:51<00:00,  1.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\nTrain Loss: 0.664 | Train Acc: 0.545\nVal. Loss: 0.726 |  Val. Acc: 0.502\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize model, criterion, and optimizer\nlstm_model_otf = LSTMClassifierOnTheFly(len(word_to_idx), embedding_dim, hidden_dim, output_dim, n_layers)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(lstm_model_otf.parameters(), lr=learning_rate)\n\n# Train the model\ntrained_lstm_model_otf = train_model(lstm_model_otf, train_loader, test_loader, criterion, optimizer, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:26:09.902254Z","iopub.execute_input":"2024-09-04T18:26:09.903097Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1/5:  84%|████████▍ | 526/625 [26:58<02:55,  1.78s/it]","output_type":"stream"}]},{"cell_type":"code","source":"print(\"RNN Model with On-the-Fly Embeddings Evaluation:\")\ntest_model(trained_rnn_model_otf, test_loader, device)\n\nprint(\"LSTM Model with On-the-Fly Embeddings Evaluation:\")\ntest_model(trained_lstm_model_otf, test_loader, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}